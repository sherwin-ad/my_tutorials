{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f01dac9f",
   "metadata": {},
   "source": [
    "# What is testing\n",
    "**Software testing**\n",
    "- The process of evaluating computer code to determine whether or it does what you expect it to do\n",
    "\n",
    "- Tests can help make good code great.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b83f84d",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "When you test software, what are you really looking for?\n",
    "\n",
    "- Loops\n",
    "\n",
    "- Conditionals\n",
    "\n",
    "- Modules\n",
    "\n",
    "- **Defects**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b91bfee",
   "metadata": {},
   "source": [
    "# Manual Testing and Automated Testing\n",
    "\n",
    "- One of the tasks that programmers had to do when writing code is test it to make sure that it behaves the way that they expected to. \n",
    "- Having good tests for our software can help us catch mistakes, errors, and bugs before we deploy our scripts to perform real-world automation tasks. \n",
    "- The most basic way of testing a script is to run it with different parameters and see if it returns the expected values. \n",
    "\n",
    "**Manual Testing**\n",
    "\n",
    "- Executing a script with different command-line arguments to see how its behavior changed is an example of manual testing. \n",
    "- Using the interpreter to try our code before putting it in a script is another form of manual testing. \n",
    "\n",
    "**Automatic Testing**\n",
    "- Formal software testing takes us process a step further, codifying tests into its own software and code that can be run to verify that our programs do what we expect them to do. - - The goal of automatic testing is to automate the process of checking if the returned value matches the expectations. \n",
    "- Instead of us humans running a function over and over with different parameters and checking the results are what we expected them to be, we let the computer do this for us. \n",
    "- Automatic testing means we'll write code to do the test. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09466148",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "The advantage of running automated tests is that they will always get the same expected ___ if the software code is good.\n",
    "\n",
    "- Parameters\n",
    "\n",
    "- Command line arguments\n",
    "\n",
    "- **Results**\n",
    "\n",
    "- Interpreters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af94442a",
   "metadata": {},
   "source": [
    "# Practice Quiz: Simple Tests\n",
    "\n",
    "1. You can verify that software code behaves correctly using test ___.\n",
    "\n",
    "- **Cases**\n",
    "\n",
    "- Loops\n",
    "\n",
    "- Arguments\n",
    "\n",
    "- Functions\n",
    "\n",
    "2. What is the most basic way of testing a script?\n",
    "\n",
    "- Codifying tests into the software.\n",
    "\n",
    "- Let a bug slip through. \n",
    "\n",
    "- Write code to do the tests.\n",
    "\n",
    "- **Different parameters with expected results.**\n",
    "\n",
    "3. When a test is codified into its own software, what kind of test is it?\n",
    "\n",
    "- Unit test\n",
    "\n",
    "- Integration test\n",
    "\n",
    "- **Automatic test**\n",
    "\n",
    "- Sanity testing\n",
    "\n",
    "4. Using _____ simplifies the testing process, allowing us to verify the program's behavior repeatedly with many possible values.\n",
    "\n",
    "- integration tests\n",
    "\n",
    "- **test cases**\n",
    "\n",
    "- test-driven development\n",
    "\n",
    "- interpreter\n",
    "\n",
    "5. The more complex our code becomes, the more value the use of _____ provides in managing errors.\n",
    "\n",
    "- loops\n",
    "\n",
    "- functions\n",
    "\n",
    "- parameters\n",
    "\n",
    "- **software testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4db828",
   "metadata": {},
   "source": [
    "# Unit Tests\n",
    "\n",
    "- Unit tests are used to verify that small isolated parts of a program are correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd003e",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "An important characteristic of a unit test is ___. \n",
    "\n",
    "- A production environment\n",
    "\n",
    "- **Isolation**.\n",
    "\n",
    "- Automation.\n",
    "\n",
    "- An external database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afc66a3",
   "metadata": {},
   "source": [
    "rearrange.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6a22e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import re\n",
    "\n",
    "def rearrange_name(name):\n",
    "    result = re.search(r\"^([\\w .]*), ([\\w .]*)$\", name)\n",
    "    return \"{} {}\".format(result[2], result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ef2901a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ada Lovelace'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rearrange import rearrange_name\n",
    "rearrange_name(\"Lovelace, Ada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a421ec",
   "metadata": {},
   "source": [
    "# Writing Unit Tests in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff711a",
   "metadata": {},
   "source": [
    "rearrange_test.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66a44fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: /Users/sherwinowen/Library/Jupyter/runtime/kernel-371d19cc-25a3-43e2-81b0-9a28629e6920 (unittest.loader._FailedTest)\n",
      "----------------------------------------------------------------------\n",
      "AttributeError: module '__main__' has no attribute '/Users/sherwinowen/Library/Jupyter/runtime/kernel-371d19cc-25a3-43e2-81b0-9a28629e6920'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3441: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from rearrange import rearrange_name\n",
    "import unittest\n",
    "\n",
    "class TestRearrage(unittest.TestCase):\n",
    "    def test_basic(self):\n",
    "        testcase = \"Lovelace, Ada\"\n",
    "        expected = \"Ada Lovelace\"\n",
    "        self.assertEqual(rearrange_name(testcase), expected)\n",
    "        \n",
    "unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5983c536",
   "metadata": {},
   "source": [
    "```\n",
    "$ chmod +x rearrange_test.py \n",
    "Owen-MBA:c2_Using Python to Interact with the Operating System sherwinowen$ ./rearrange_test.py \n",
    ".\n",
    "----------------------------------------------------------------------\n",
    "Ran 1 test in 0.000s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c60adf",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "What module can you load to use a bunch of testing methods for your unit tests?\n",
    "\n",
    "- **unittest**\n",
    "\n",
    "- assertEqual\n",
    "\n",
    "- Test\n",
    "\n",
    "- TestCase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e48a5e",
   "metadata": {},
   "source": [
    "# Edge Cases\n",
    "\n",
    "- Edge cases are inputs to our code that produce unexpected results, and are found at the extreme ends of the ranges of input we imagine our programs will typically work with. \n",
    "- Edge cases usually need special handling in scripts in order for the code to continue to behave correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40549564",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "Which of the following would NOT be considered as an edge case when testing a software's input for a user's first and last name?\n",
    "\n",
    "- **Jeffrey**\n",
    "\n",
    "- Ben05\n",
    "\n",
    "- 0\n",
    "\n",
    "- -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d16904",
   "metadata": {},
   "outputs": [],
   "source": [
    "rearrange_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01062075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from rearrange import rearrange_name\n",
    "import unittest\n",
    "\n",
    "class TestRearrage(unittest.TestCase):\n",
    "    def test_basic(self):\n",
    "        testcase = \"Lovelace, Ada\"\n",
    "        expected = \"Ada Lovelace\"\n",
    "        self.assertEqual(rearrange_name(testcase), expected)\n",
    "    \n",
    "    def test_empty(self):\n",
    "        testcase = \"\"\n",
    "        expected = \"\"\n",
    "        self.assertEqual(rearrange_name(testcase), expected)\n",
    "            \n",
    "unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb2a0af",
   "metadata": {},
   "source": [
    "```\n",
    "$ ./rearrange_test.py \n",
    ".E\n",
    "======================================================================\n",
    "ERROR: test_empty (__main__.TestRearrage)\n",
    "----------------------------------------------------------------------\n",
    "Traceback (most recent call last):\n",
    "  File \"/Users/sherwinowen/my_doc/my_tutorials/python/Google_IT_Automation_with_Python/c2_Using Python to Interact with the Operating System/./rearrange_test.py\", line 15, in test_empty\n",
    "    self.assertEqual(rearrange_name(testcase), expected)\n",
    "  File \"/Users/sherwinowen/my_doc/my_tutorials/python/Google_IT_Automation_with_Python/c2_Using Python to Interact with the Operating System/rearrange.py\", line 7, in rearrange_name\n",
    "    return \"{} {}\".format(result[2], result[1])\n",
    "TypeError: 'NoneType' object is not subscriptable\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Ran 2 tests in 0.001s\n",
    "\n",
    "FAILED (errors=1)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af070c9",
   "metadata": {},
   "source": [
    "rearrange.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd3fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import re\n",
    "\n",
    "def rearrange_name(name):\n",
    "    result = re.search(r\"^([\\w .]*), ([\\w .]*)$\", name)\n",
    "    if result is None:\n",
    "        return \"\"\n",
    "    return \"{} {}\".format(result[2], result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f3827f",
   "metadata": {},
   "source": [
    "```\n",
    "$ ./rearrange_test.py \n",
    "..\n",
    "----------------------------------------------------------------------\n",
    "Ran 2 tests in 0.000s\n",
    "\n",
    "OK\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6c52c0",
   "metadata": {},
   "source": [
    "# Additional Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb0b3d3",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "Which of the following is NOT an advantage of running an automatic unit test in a suite for a single function?\n",
    "\n",
    "\n",
    "- Creating one script for multiple test cases\n",
    "\n",
    "- **Creating multiple test scripts**\n",
    "\n",
    "- Reusable test cases\n",
    "\n",
    "- Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a46ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from rearrange import rearrange_name\n",
    "import unittest\n",
    "\n",
    "class TestRearrage(unittest.TestCase):\n",
    "    def test_basic(self):\n",
    "        testcase = \"Lovelace, Ada\"\n",
    "        expected = \"Ada Lovelace\"\n",
    "        self.assertEqual(rearrange_name(testcase), expected)\n",
    "    \n",
    "    def test_empty(self):\n",
    "        testcase = \"\"\n",
    "        expected = \"\"\n",
    "        self.assertEqual(rearrange_name(testcase), expected)\n",
    "        \n",
    "    def test_double_name(self):\n",
    "        testcase = \"Hopper, Grace M.\"\n",
    "        expected = \"Grace M. Hopper\"\n",
    "        self.assertEqual(rearrange_name(testcase), expected)\n",
    "        \n",
    "    def test_one_name(self):\n",
    "        testcase = \"Voltaire\"\n",
    "        expected = \"Voltaire\"\n",
    "        self.assertEqual(rearrange_name(testcase), expected)\n",
    "            \n",
    "unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc22efc2",
   "metadata": {},
   "source": [
    "```\n",
    "$ ./rearrange_test.py \n",
    "...F\n",
    "======================================================================\n",
    "FAIL: test_one_name (__main__.TestRearrage)\n",
    "----------------------------------------------------------------------\n",
    "Traceback (most recent call last):\n",
    "  File \"/Users/sherwinowen/my_doc/my_tutorials/python/Google_IT_Automation_with_Python/c2_Using Python to Interact with the Operating System/./rearrange_test.py\", line 25, in test_one_name\n",
    "    self.assertEqual(rearrange_name(testcase), expected)\n",
    "AssertionError: '' != 'Voltaire'\n",
    "+ Voltaire\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Ran 4 tests in 0.000s\n",
    "\n",
    "FAILED (failures=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "244d27e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import re\n",
    "\n",
    "def rearrange_name(name):\n",
    "    result = re.search(r\"^([\\w .]*), ([\\w .]*)$\", name)\n",
    "    if result is None:\n",
    "        return name\n",
    "    return \"{} {}\".format(result[2], result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f624146",
   "metadata": {},
   "source": [
    "```\n",
    "$ ./rearrange_test.py \n",
    "....\n",
    "----------------------------------------------------------------------\n",
    "Ran 4 tests in 0.000s\n",
    "\n",
    "OK\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7d5feb",
   "metadata": {},
   "source": [
    "# Unit Test Cheat-Sheet\n",
    "\n",
    "Frankly, the unit testing library for Python is fairly well documented, but it can be a bit of a dry read. Instead, we suggest covering the core module concepts, and then reading in more detail later.\n",
    "\n",
    "### Best of Unit Testing Standard Library Module\n",
    "\n",
    "Understand a Basic Example:\n",
    "\n",
    "- https://docs.python.org/3/library/unittest.html#basic-example\n",
    "\n",
    "Understand how to run the tests using the Command Line:\n",
    "\n",
    "- https://docs.python.org/3/library/unittest.html#command-line-interface\n",
    "\n",
    "Understand various Unit Test Design Patterns:\n",
    "\n",
    "- https://docs.python.org/3/library/unittest.html#organizing-test-code\n",
    "\n",
    "- Understand the uses of setUp, tearDown; setUpModule and tearDownModule\n",
    "\n",
    "Understand basic assertions:\n",
    "\n",
    "| **Method**                                                   | **Checks that**      | **New in** |\n",
    "| :----------------------------------------------------------- | :------------------- | :--------- |\n",
    "| [assertEqual(a, b)](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertEqual) | a == b               |            |\n",
    "| [assertNotEqual(a, b)](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertNotEqual) | a != b               |            |\n",
    "| [assertTrue(x)](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertTrue) | bool(x) is True      |            |\n",
    "| [assertFalse(x)](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertFalse) | bool(x) is False     |            |\n",
    "| [assertIs(a, b)](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertIs) | a is b               | 3.1        |\n",
    "| [assertIsNot(a, b)](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertIsNot) | a is not b           | 3.1        |\n",
    "| [assertIsNone(x)](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertIsNone) | x is None            | 3.1        |\n",
    "| [assertIsNotNone(x)](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertIsNotNone) | x is not None        | 3.1        |\n",
    "| [assertIn(a, b)](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertIn) | a in b               | 3.1        |\n",
    "| [assertNotIn(a, b)](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertNotIn) | a not in b           | 3.1        |\n",
    "| [assertIsInstance(a, b)](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertIsInstance) | isinstance(a, b)     | 3.2        |\n",
    "| [assertNotIsInstance(a, b)](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertNotIsInstance) | not isinstance(a, b) | 3.2        |\n",
    "\n",
    "\n",
    "\n",
    "Understand more specific assertions such as assertRaises\n",
    "\n",
    "- https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertRaises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff8d3a0",
   "metadata": {},
   "source": [
    "# Help with Jupyter Notebooks\n",
    "\n",
    "We've aimed to make our Jupyter notebooks easy to use. But, if you get stuck, you can find more information [here](https://learner.coursera.help/hc/en-us/articles/360004995312-Solve-problems-with-Jupyter-Notebooks).\n",
    "\n",
    "If you still need help, the discussion forums are a great place to find it! Use the forums to ask questions and source answers from your fellow learners.\n",
    "\n",
    "If you want to learn more about Jupyter Notebooks as a technology, check out these resources:\n",
    "\n",
    "- [Jupyter Notebook Tutorial](https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook), by datacamp.com\n",
    "- [How to use Jupyter Notebooks](https://www.codecademy.com/articles/how-to-use-jupyter-notebooks), by codeacademy.com\n",
    "- [Teaching and Learning with Jupyter](https://jupyter4edu.github.io/jupyter-edu-book/), by university professors using Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea75cb4",
   "metadata": {},
   "source": [
    "# Other Test Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e06526",
   "metadata": {},
   "source": [
    "# Black Box vs. White Box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d2937",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "Which of the following is descriptive of a black-box test case?\n",
    "\n",
    "\n",
    "- The tester is familiar with the code.\n",
    "\n",
    "- Tests are created alongside the code development.\n",
    "\n",
    "- The code is open-source.\n",
    "\n",
    "- **Code is opaque.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3e74ba",
   "metadata": {},
   "source": [
    "# Other Test Types\n",
    "\n",
    "**Integration Tests** \n",
    "- verify that the interactions between the different pieces of code in integrated environments are working the way we expect them to\n",
    "- integration tests verify that the interactions between the different pieces of code in integrated environments are working the way we expect them to\n",
    "- usually take the individual modules of code that unit test verify then combine them into a group to test.\n",
    "\n",
    "**Regression Tests**\n",
    "- They're usually written as part of a debugging and troubleshooting process to verify that an issue or error has been fixed once it's been identified. \n",
    "- Say our script has a bug and we're trying to fix it. A good approach to doing this would be the first right to test fails by triggering the buggy behavior, then fix the bug so that a test passes. \n",
    "- Regression tests are useful part of a test suite because they ensure that the same mistake doesn't happen twice. The same bug can't be reintroduced into the code because introducing it will cause the regression test to fail.\n",
    "\n",
    "**Smoke Test (Build Verification Test)**\n",
    "- get their name from a concept that comes from testing hardware equipment. Plug in the given piece of hardware and see if smoke starts coming out of it. When writing software smoke test serve as a kind of sanity check to find major bugs in a program. \n",
    "- Smoke test answer basic questions like, does the program run? These tests are usually run before more refined testing takes place. Since if the software fails the smoke test you can be pretty sure none of the other tests will pass either. As they say where there's smoke there's fire.\n",
    "\n",
    "**Load Tests**\n",
    "- These tests verify that the system behaves well when it's under significant load. \n",
    "- To actually perform these tests will need to generate traffic to our application simulating typical usage of the service. \n",
    "- These tests can be super-helpful when deploying new versions of our applications to verify that performance does not degrade. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad6dc90",
   "metadata": {},
   "source": [
    "Running a piece of software code as-is to see if it runs describes what type of testing?\n",
    "\n",
    "- Regression test\n",
    "\n",
    "- **Smoke test**\n",
    "\n",
    "- Load test\n",
    "\n",
    "- Integration test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830df721",
   "metadata": {},
   "source": [
    "# Test-Driven Development\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c56a8",
   "metadata": {},
   "source": [
    "# Question\n",
    "Which of the following is NOT an advantage of test-driven development (TDD)?\n",
    "\n",
    "- **Faster development of code**\n",
    "\n",
    "- A problem is well thought out\n",
    "\n",
    "- Test while you develop code\n",
    "\n",
    "- Test cases written before writing code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34506e4c",
   "metadata": {},
   "source": [
    "# More About Tests\n",
    "\n",
    "Check out the following links for more information:\n",
    "\n",
    "- https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems/\n",
    "- https://landing.google.com/sre/sre-book/chapters/testing-reliability/\n",
    "\n",
    "- https://testing.googleblog.com/2007/10/performance-testing.html\n",
    "- https://www.guru99.com/smoke-testing.html\n",
    "- https://www.guru99.com/exploratory-testing.html\n",
    "- https://testing.googleblog.com/2008/09/test-first-is-fun_08.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c7397c",
   "metadata": {},
   "source": [
    "# Practice Quiz: Other Test Concepts\n",
    "\n",
    "1. In what type of test is the code not transparent?\n",
    "\n",
    "- Test-driven development\n",
    "\n",
    "- **Black-box test**\n",
    "\n",
    "- Smoke test\n",
    "\n",
    "- White-box test\n",
    "\n",
    "2. Verifying an automation script works well with the overall system and external entities describes what type of test?\n",
    "\n",
    "- Smoke test\n",
    "\n",
    "- Regression test\n",
    "\n",
    "- **Integration test**\n",
    "\n",
    "- Load test\n",
    "\n",
    "3. _____ ensures that any success or failure of a unit test is caused by the behavior of the unit in question, and doesn't result from some external factor.\n",
    "\n",
    "- Regression testing\n",
    "\n",
    "- Integration\n",
    "\n",
    "- **Isolation**\n",
    "\n",
    "- White-box testing\n",
    "\n",
    "4. A test that is written after a bug has been identified in order to ensure the bug doesn't show up again later is called _____\n",
    "\n",
    "- Load test\n",
    "\n",
    "- Black-box test\n",
    "\n",
    "- Smoke test\n",
    "\n",
    "- **Regression test**\n",
    "\n",
    "5. What type of software testing is used to verify the software’s ability to behave well under significantly stressed testing conditions?\n",
    "\n",
    "- **Load test**\n",
    "\n",
    "- Black-box test\n",
    "\n",
    "- Smoke test\n",
    "\n",
    "- Regression test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836314cb",
   "metadata": {},
   "source": [
    "# Try-Except Construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42fbd0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "def character_frequency (filename):\n",
    "    \"\"\"Counts the frequency of each character in the given file.\"\"\"\n",
    "    # First try to open the file\n",
    "    try:\n",
    "        f = open (filename)\n",
    "    except OSError:\n",
    "        return None\n",
    "\n",
    "    # Now process the file\n",
    "    characters = {}\n",
    "    for line in f:\n",
    "        for char in line:\n",
    "            characters[char] = characters.get(char, 0) + 1\n",
    "    f.close()\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2815af4",
   "metadata": {},
   "source": [
    "- So when writing a try-except block, the important thing to remember is that the code in the except block is only executed if one of the instructions in the try block raise an error of the matching type. \n",
    "- We could also decide to set a variable to some base value like: \n",
    "  - zero for numbers, \n",
    "  - empty string for strings, \n",
    "  - empty list for list,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2630f2",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "When a try block is not able to execute a function, which of the following return examples will an exception block most likely NOT return?\n",
    "\n",
    "- Empty String\n",
    "\n",
    "- Empty List\n",
    "\n",
    "- **Error**\n",
    "\n",
    "- Zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf6121b",
   "metadata": {},
   "source": [
    "# Raising Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc49929",
   "metadata": {},
   "source": [
    "Raise\n",
    "- the keyword to generate an error in Python\n",
    "\n",
    "- We can raise a bunch of different errors that come already pre-built with Python or we can create our own, if the standard ones aren't good enough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a4ebb6",
   "metadata": {},
   "source": [
    "validations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e892647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "def validate_user(username, minlen):\n",
    "    if minlen < 1:\n",
    "        raise ValueError(\"minlen must be at least 1\")\n",
    "    if len(username) < minlen:\n",
    "        return False\n",
    "    if not username.isalnum():\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae5571a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "minlen must be at least 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvalidations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_user\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvalidate_user\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_doc/my_tutorials/python/Google_IT_Automation_with_Python/c2_Using Python to Interact with the Operating System/validations.py:5\u001b[0m, in \u001b[0;36mvalidate_user\u001b[0;34m(username, minlen)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_user\u001b[39m(username, minlen):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m minlen \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminlen must be at least 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(username) \u001b[38;5;241m<\u001b[39m minlen:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: minlen must be at least 1"
     ]
    }
   ],
   "source": [
    "from validations import validate_user\n",
    "validate_user(\"\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f97e14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from validations import validate_user\n",
    "validate_user(\"\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f43e69c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from validations import validate_user\n",
    "validate_user(\"myuser\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9114f6e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvalidations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_user\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvalidate_user\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m88\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_doc/my_tutorials/python/Google_IT_Automation_with_Python/c2_Using Python to Interact with the Operating System/validations.py:6\u001b[0m, in \u001b[0;36mvalidate_user\u001b[0;34m(username, minlen)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m minlen \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminlen must be at least 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43musername\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m minlen:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m username\u001b[38;5;241m.\u001b[39misalnum():\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "from validations import validate_user\n",
    "validate_user(88, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e64b1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
